from typing import Optional
from langchain_core.pydantic_v1 import BaseModel, Field

class ClassificationLabels(BaseModel):
    class_label:str = Field(description='The class label of the user query')
    subclass_label: str = Field(description='The subclass label of the user query')

class QueryRewriter(BaseModel):
    search_query:str = Field(description='The modified final search query that improves retrievability')

class QueryResponse(BaseModel):
    answer:str = Field(description='The answer to user query from the customer support agent')
    followup_questions: list[str] = Field(description='Exactly 3 new follow-up questions that can be answered from the context provided')

class ChatRequest(BaseModel):
    query: str = Field(description="User query")
    session_id:str = Field(description="Session ID from the frontend") 

class ChatResponse(BaseModel):
    query: str = Field(description="User query")
    answer: Optional[str] = Field(description="Response generated by the LLM")
    followup_questions: Optional[list[str]] = Field(description="Follow-up questions generated by the LLM")
    session_id: str = Field(description="Session ID from the frontend")
    conversation_id: str = Field(description="Conversation inside a session, 1 run = 1 conversation")
    class_label:str = Field(description="Classification label of the user query")
    subclass_label: str = Field(description="Subclass label of the user query")
    context_id: Optional[list[str]] = Field(description="ID of the top-k relevant documents used to answer")
    search_query: Optional[str] = Field(description="Modified user query used for retrieving relevant documents")
    hallucination_flag: Optional[str] = Field(description="Hallucination flag hints about potential hallucination present in anaswer")
    total_time: float = Field(description="Total time taken to process the query",gt=0)
    prompt_tokens: int = Field(description="Input token length",gt=0)
    completion_tokens: int = Field(description="Output token length",gt=0)
    total_tokens: int = Field(description="Input + output tokens",gt=0)
    total_cost: float = Field(description="Total cost of the query",gt=0.0)
    model_name: str = Field(description="Name and version of the LLM used")
    timestamp: str = Field(description="Timestamp at which the answer is sent back")    
    memory: Optional[list[tuple]] = Field(description="Last 3 conversation pairs")
    context: Optional[str] = Field(description="Concatenated context for debug")